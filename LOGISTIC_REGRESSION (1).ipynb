{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MVbv8eWW1co",
        "outputId": "7592fc98-0b8c-42f5-ddbc-fdd098ffac5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Parameters (Theta): [-5.43746411  1.11202123]\n",
            "Predictions: [0 0 0 1 1 1 1 0 0 0 0 1 1 1 1]\n",
            "Accuracy: 93.33%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    cost = (-1 / m) * (y.T.dot(np.log(h)) + (1 - y).T.dot(np.log(1 - h)))\n",
        "    return cost\n",
        "\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, iterations):\n",
        "    m = len(y)\n",
        "    for _ in range(iterations):\n",
        "        h = sigmoid(X.dot(theta))\n",
        "        gradient = (1 / m) * X.T.dot(h - y)\n",
        "        theta -= alpha * gradient\n",
        "    return theta\n",
        "\n",
        "\n",
        "def logistic_regression(X, y, alpha=0.01, iterations=1000):\n",
        "    X = np.c_[np.ones(X.shape[0]), X]\n",
        "    theta = np.zeros(X.shape[1])\n",
        "    theta = gradient_descent(X, y, theta, alpha, iterations)\n",
        "    return theta\n",
        "\n",
        "\n",
        "def predict(X, theta, threshold=0.5):\n",
        "    X = np.c_[np.ones(X.shape[0]), X]\n",
        "    probabilities = sigmoid(X.dot(theta))\n",
        "    return (probabilities >= threshold).astype(int)\n",
        "\n",
        "X = np.array([\n",
        "    [2.5], [1.0], [3.5], [5.0], [7.0],\n",
        "    [6.0], [8.5], [4.0], [1.5], [3.0],\n",
        "    [2.0], [6.5], [8.0], [7.5], [5.5]\n",
        "])\n",
        "\n",
        "y = np.array([\n",
        "    0, 0, 0, 1, 1,\n",
        "    1, 1, 0, 0, 0,\n",
        "    0, 1, 1, 1, 0\n",
        "])\n",
        "\n",
        "\n",
        "theta = logistic_regression(X, y, alpha=0.1, iterations=1000)\n",
        "\n",
        "\n",
        "predictions = predict(X, theta)\n",
        "accuracy = np.mean(predictions == y)\n",
        "\n",
        "print(f\"Trained Parameters (Theta): {theta}\")\n",
        "print(f\"Predictions: {predictions}\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    }
  ]
}